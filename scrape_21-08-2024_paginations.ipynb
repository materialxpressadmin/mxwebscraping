{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43fc5fe1-6fa8-4e70-b6ca-4ded5800e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is for scraping multiple pages using Selenium & more libraries and tools\n",
    "# Title >  Scraping multiples pages data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45e8c0c-c2b3-4f44-b523-8f2751a4234c",
   "metadata": {},
   "source": [
    "# Note book   1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07291de7-1aba-44d2-9592-0d6548d3c360",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "WebDriver.__init__() got multiple values for argument 'options'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# web = \"https://www.audible.com/search\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAved Debbarma\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mchromedriver\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mchromedriver-win64\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mchromedriver.exe\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 22\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(web)\n\u001b[0;32m     24\u001b[0m driver\u001b[38;5;241m.\u001b[39mmaximize_window()\n",
      "\u001b[1;31mTypeError\u001b[0m: WebDriver.__init__() got multiple values for argument 'options'"
     ]
    }
   ],
   "source": [
    "# from selenium import webdriver\n",
    "# import pandas as pd\n",
    "# import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "options = Options()\n",
    "options.headless = False\n",
    "web = \"https://www.audible.com/adblbestsellers?ref=a_search_t1_navTop_pl0cg1c0r0&pf_rd_p=adc4b13b-d074-4e1c-ac46-9f54aa53072b&pf_rd_r=1F7DV0MPHV77Z61RX566\"\n",
    "\n",
    "# web = \"https://www.audible.com/search\"\n",
    "path = r'C:\\Users\\Aved Debbarma\\Downloads\\chromedriver\\chromedriver-win64\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(path, options = options)\n",
    "driver.get(web)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Pagination 1\n",
    "pagination = driver.find_element_by_xpath('//ul[contains(@class, \"pagingElements\")]')  # locating pagination bar\n",
    "pages = pagination.find_elements_by_tag_name('li')  # locating each page displayed in the pagination bar\n",
    "last_page = int(pages[-2].text)  # getting the last page with negative indexing (starts from where the array ends)\n",
    "\n",
    "book_title = []\n",
    "book_author = []\n",
    "book_length = []\n",
    "\n",
    "# Pagination 2\n",
    "current_page = 1   # this is the page the bot starts scraping\n",
    "\n",
    "# The while loop below will work until the the bot reaches the last page of the website, then it will break\n",
    "while current_page <= last_page:\n",
    "    time.sleep(2)  # let the page render correctly\n",
    "    container = driver.find_element_by_class_name('adbl-impression-container ')\n",
    "    products = container.find_elements_by_xpath('.//li[contains(@class, \"productListItem\")]')\n",
    "    # products = container.find_elements_by_xpath('./li')\n",
    "\n",
    "    for product in products:\n",
    "        book_title.append(product.find_element_by_xpath('.//h3[contains(@class, \"bc-heading\")]').text)\n",
    "        book_author.append(product.find_element_by_xpath('.//li[contains(@class, \"authorLabel\")]').text)\n",
    "        book_length.append(product.find_element_by_xpath('.//li[contains(@class, \"runtimeLabel\")]').text)\n",
    "\n",
    "    current_page = current_page + 1  # increment the current_page by 1 after the data is extracted\n",
    "    # Locating the next_page button and clicking on it. If the element isn't on the website, pass to the next iteration\n",
    "    try:\n",
    "        next_page = driver.find_element_by_xpath('.//span[contains(@class , \"nextButton\")]')\n",
    "        next_page.click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df_books = pd.DataFrame({'title': book_title, 'author': book_author, 'length': book_length})\n",
    "df_books.to_csv('books_pagination.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12153886-d135-4882-bb7d-4784da30922d",
   "metadata": {},
   "source": [
    "# # Note book  2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec3b80e-b5fe-484d-a171-156a9d80b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "options = Options()\n",
    "options.headless = False\n",
    "web = \"https://www.audible.com/adblbestsellers?ref=a_search_t1_navTop_pl0cg1c0r0&pf_rd_p=adc4b13b-d074-4e1c-ac46-9f54aa53072b&pf_rd_r=1F7DV0MPHV77Z61RX566\"\n",
    "\n",
    "path = r'C:\\Users\\Aved Debbarma\\Downloads\\chromedriver\\chromedriver-win64\\chromedriver.exe'\n",
    "service = Service(executable_path=path)\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get(web)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Pagination 1\n",
    "pagination = driver.find_element(By.XPATH, '//ul[contains(@class, \"pagingElements\")]')  # locating pagination bar\n",
    "pages = pagination.find_elements(By.TAG_NAME, 'li')  # locating each page displayed in the pagination bar\n",
    "last_page = int(pages[-2].text)  # getting the last page with negative indexing (starts from where the array ends)\n",
    "\n",
    "book_title = []\n",
    "book_author = []\n",
    "book_length = []\n",
    "\n",
    "# Pagination 2\n",
    "current_page = 1   # this is the page the bot starts scraping\n",
    "\n",
    "# The while loop below will work until the bot reaches the last page of the website, then it will break\n",
    "while current_page <= last_page:\n",
    "    time.sleep(2)  # let the page render correctly\n",
    "    container = driver.find_element(By.CLASS_NAME, 'adbl-impression-container ')\n",
    "    products = container.find_elements(By.XPATH, './/li[contains(@class, \"productListItem\")]')\n",
    "\n",
    "    for product in products:\n",
    "        book_title.append(product.find_element(By.XPATH, './/h3[contains(@class, \"bc-heading\")]').text)\n",
    "        book_author.append(product.find_element(By.XPATH, './/li[contains(@class, \"authorLabel\")]').text)\n",
    "        book_length.append(product.find_element(By.XPATH, './/li[contains(@class, \"runtimeLabel\")]').text)\n",
    "\n",
    "    current_page += 1  # increment the current_page by 1 after the data is extracted\n",
    "    # Locating the next_page button and clicking on it. If the element isn't on the website, pass to the next iteration\n",
    "    try:\n",
    "        next_page = driver.find_element(By.XPATH, './/span[contains(@class , \"nextButton\")]')\n",
    "        next_page.click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df_books = pd.DataFrame({'title': book_title, 'author': book_author, 'length': book_length})\n",
    "df_books.to_csv('books_pagination.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0062507b-80d3-4558-a6cd-b81891564b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['By: Colleen Hoover',\n",
       "  'By: Ryan Holiday',\n",
       "  'By: Freida McFadden',\n",
       "  'By: Sarah J. Maas',\n",
       "  'By: Luis Elizondo',\n",
       "  'By: Colleen Hoover',\n",
       "  'By: Sarah J. Maas',\n",
       "  'By: Amy Harmon',\n",
       "  'By: Rebecca Yarros',\n",
       "  'By: Rebecca Yarros',\n",
       "  'By: Sarah J. Maas',\n",
       "  'By: James S.A. Corey',\n",
       "  'By: J. D. Vance',\n",
       "  'By: Freida McFadden',\n",
       "  'By: Jennifer L. Armentrout',\n",
       "  'By: Freida McFadden',\n",
       "  'By: Morgan Housel',\n",
       "  'By: Brian Tyler Cohen',\n",
       "  'By: Shelby Van Pelt',\n",
       "  'By: Steve Benen'],\n",
       " ['Length: 11 hrs and 11 mins',\n",
       "  'Length: 6 hrs and 56 mins',\n",
       "  'Length: 9 hrs and 46 mins',\n",
       "  'Length: 23 hrs and 16 mins',\n",
       "  'Length: 10 hrs',\n",
       "  'Length: 8 hrs and 10 mins',\n",
       "  'Length: 25 hrs and 9 mins',\n",
       "  'Length: 13 hrs and 44 mins',\n",
       "  'Length: 21 hrs and 22 mins',\n",
       "  'Length: 28 hrs and 16 mins',\n",
       "  'Length: 26 hrs and 5 mins',\n",
       "  'Length: 14 hrs and 54 mins',\n",
       "  'Length: 6 hrs and 49 mins',\n",
       "  'Length: 11 hrs and 42 mins',\n",
       "  'Length: 37 hrs and 1 min',\n",
       "  'Length: 9 hrs and 44 mins',\n",
       "  'Length: 5 hrs and 55 mins',\n",
       "  'Length: 4 hrs and 38 mins',\n",
       "  'Length: 11 hrs and 16 mins',\n",
       "  'Length: 5 hrs and 38 mins'],\n",
       " ['1. It Ends with Us',\n",
       "  '2. Ego Is the Enemy',\n",
       "  '3. The Housemaid',\n",
       "  '4. A Court of Mist and Fury',\n",
       "  '5. Imminent',\n",
       "  '6. Verity',\n",
       "  '7. A Court of Wings and Ruin',\n",
       "  '8. The Outlaw Noble Salt',\n",
       "  '9. Fourth Wing',\n",
       "  '10. Iron Flame',\n",
       "  '11. A Court of Silver Flames',\n",
       "  '12. The Mercy of Gods',\n",
       "  '13. Hillbilly Elegy',\n",
       "  '14. The Housemaid Is Watching',\n",
       "  '15. Born of Blood and Ash',\n",
       "  \"16. The Housemaid's Secret\",\n",
       "  '17. The Psychology of Money',\n",
       "  '18. Shameless',\n",
       "  '19. Remarkably Bright Creatures',\n",
       "  '20. Ministry of Truth'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_author,book_length,book_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933682f0-6ac5-495e-b335-9664bb20058a",
   "metadata": {},
   "source": [
    "#  Note book  3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad5fce2-2a83-4985-92e4-9b4474b04581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "options = Options()\n",
    "options.headless = False\n",
    "web = \"https://www.audible.com/adblbestsellers?ref=a_search_t1_navTop_pl0cg1c0r0&pf_rd_p=adc4b13b-d074-4e1c-ac46-9f54aa53072b&pf_rd_r=1F7DV0MPHV77Z61RX566\"\n",
    "\n",
    "path = r'C:\\Users\\Aved Debbarma\\Downloads\\chromedriver\\chromedriver-win64\\chromedriver.exe'\n",
    "service = Service(executable_path=path)\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get(web)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Pagination 1\n",
    "pagination = driver.find_element(By.XPATH, '//ul[contains(@class, \"pagingElements\")]')  # locating pagination bar\n",
    "pages = pagination.find_elements(By.TAG_NAME, 'li')  # locating each page displayed in the pagination bar\n",
    "last_page = int(pages[-2].text)  # getting the last page with negative indexing (starts from where the array ends)\n",
    "\n",
    "book_title = []\n",
    "book_author = []\n",
    "book_length = []\n",
    "\n",
    "# Pagination 2\n",
    "current_page = 1   # this is the page the bot starts scraping\n",
    "\n",
    "# The while loop below will work until the bot reaches the last page of the website, then it will break\n",
    "while current_page <= last_page:\n",
    "    time.sleep(2)  # let the page render correctly\n",
    "    container = driver.find_element(By.CLASS_NAME, 'adbl-impression-container ')\n",
    "    products = container.find_elements(By.XPATH, './/li[contains(@class, \"productListItem\")]')\n",
    "\n",
    "    for product in products:\n",
    "        book_title.append(product.find_element(By.XPATH, './/h3[contains(@class, \"bc-heading\")]').text)\n",
    "        book_author.append(product.find_element(By.XPATH, './/li[contains(@class, \"authorLabel\")]').text)\n",
    "        book_length.append(product.find_element(By.XPATH, './/li[contains(@class, \"runtimeLabel\")]').text)\n",
    "\n",
    "    current_page += 1  # increment the current_page by 1 after the data is extracted\n",
    "    # Locating the next_page button and clicking on it. If the element isn't on the website, pass to the next iteration\n",
    "    try:\n",
    "        next_page = driver.find_element(By.XPATH, './/span[contains(@class , \"nextButton\")]')\n",
    "        next_page.click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df_books = pd.DataFrame({'title': book_title, 'author': book_author, 'length': book_length})\n",
    "df_books.to_csv('books_pagination.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5034a02a-f137-415d-b366-01a2e2633804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['By: Colleen Hoover',\n",
       "  'By: Ryan Holiday',\n",
       "  'By: Freida McFadden',\n",
       "  'By: Sarah J. Maas',\n",
       "  'By: Luis Elizondo',\n",
       "  'By: Colleen Hoover',\n",
       "  'By: Sarah J. Maas',\n",
       "  'By: Amy Harmon',\n",
       "  'By: Rebecca Yarros',\n",
       "  'By: Rebecca Yarros',\n",
       "  'By: Sarah J. Maas',\n",
       "  'By: James S.A. Corey',\n",
       "  'By: J. D. Vance',\n",
       "  'By: Freida McFadden',\n",
       "  'By: Jennifer L. Armentrout',\n",
       "  'By: Freida McFadden',\n",
       "  'By: Morgan Housel',\n",
       "  'By: Brian Tyler Cohen',\n",
       "  'By: Shelby Van Pelt',\n",
       "  'By: Steve Benen'],\n",
       " ['Length: 11 hrs and 11 mins',\n",
       "  'Length: 6 hrs and 56 mins',\n",
       "  'Length: 9 hrs and 46 mins',\n",
       "  'Length: 23 hrs and 16 mins',\n",
       "  'Length: 10 hrs',\n",
       "  'Length: 8 hrs and 10 mins',\n",
       "  'Length: 25 hrs and 9 mins',\n",
       "  'Length: 13 hrs and 44 mins',\n",
       "  'Length: 21 hrs and 22 mins',\n",
       "  'Length: 28 hrs and 16 mins',\n",
       "  'Length: 26 hrs and 5 mins',\n",
       "  'Length: 14 hrs and 54 mins',\n",
       "  'Length: 6 hrs and 49 mins',\n",
       "  'Length: 11 hrs and 42 mins',\n",
       "  'Length: 37 hrs and 1 min',\n",
       "  'Length: 9 hrs and 44 mins',\n",
       "  'Length: 5 hrs and 55 mins',\n",
       "  'Length: 4 hrs and 38 mins',\n",
       "  'Length: 11 hrs and 16 mins',\n",
       "  'Length: 5 hrs and 38 mins'],\n",
       " ['1. It Ends with Us',\n",
       "  '2. Ego Is the Enemy',\n",
       "  '3. The Housemaid',\n",
       "  '4. A Court of Mist and Fury',\n",
       "  '5. Imminent',\n",
       "  '6. Verity',\n",
       "  '7. A Court of Wings and Ruin',\n",
       "  '8. The Outlaw Noble Salt',\n",
       "  '9. Fourth Wing',\n",
       "  '10. Iron Flame',\n",
       "  '11. A Court of Silver Flames',\n",
       "  '12. The Mercy of Gods',\n",
       "  '13. Hillbilly Elegy',\n",
       "  '14. The Housemaid Is Watching',\n",
       "  '15. Born of Blood and Ash',\n",
       "  \"16. The Housemaid's Secret\",\n",
       "  '17. The Psychology of Money',\n",
       "  '18. Shameless',\n",
       "  '19. Remarkably Bright Creatures',\n",
       "  '20. Ministry of Truth'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_author,book_length,book_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a96694-2a47-4b6e-9010-0d83e6e3fc00",
   "metadata": {},
   "source": [
    "# Note book  4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad691d-734c-4b5b-89a3-125b1243a419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new libraries added \n",
    "# *by \n",
    "# *exprected_conditions\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "options = Options()\n",
    "options.headless = False\n",
    "web = \"https://www.audible.com/adblbestsellers?ref=a_search_t1_navTop_pl0cg1c0r0&pf_rd_p=adc4b13b-d074-4e1c-ac46-9f54aa53072b&pf_rd_r=1F7DV0MPHV77Z61RX566\"\n",
    "\n",
    "path = r'C:\\Users\\Aved Debbarma\\Downloads\\chromedriver\\chromedriver-win64\\chromedriver.exe'\n",
    "service = Service(executable_path=path)\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get(web)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Pagination 1\n",
    "pagination = driver.find_element(By.XPATH, '//ul[contains(@class, \"pagingElements\")]')  # locating pagination bar\n",
    "pages = pagination.find_elements(By.TAG_NAME, 'li')  # locating each page displayed in the pagination bar\n",
    "last_page = int(pages[-2].text)  \n",
    "\n",
    "book_title = []\n",
    "book_author = []\n",
    "book_length = []\n",
    "\n",
    "# Pagination 2\n",
    "current_page = 1   # this is the page the bot starts scraping\n",
    "\n",
    "while current_page <= last_page:\n",
    "    # time.sleep(2)\n",
    "    container = WebDriverWait(driver, 5).until(EC.presence_of_all_elements_located(By.CLASS_NAME, 'adbl-impression-container ') #changes done here\n",
    "    # container = driver.find_element(By.CLASS_NAME, 'adbl-impression-container ') changed with above line\n",
    "    \n",
    "    # products = container.find_elements(By.XPATH, './li')\n",
    "    products = WebDriverWait(container, 5).until(EC.presence_of_all_elements_located(By.XPATH, './li'))\n",
    "\n",
    "    for product in products:\n",
    "        book_title.append(product.find_element(By.XPATH, './/h3[contains(@class, \"bc-heading\")]').text)\n",
    "        book_author.append(product.find_element(By.XPATH, './/li[contains(@class, \"authorLabel\")]').text)\n",
    "        book_length.append(product.find_element(By.XPATH, './/li[contains(@class, \"runtimeLabel\")]').text)\n",
    "\n",
    "    current_page += 1  \n",
    "    try:\n",
    "        next_page = driver.find_element(By.XPATH, './/span[contains(@class , \"nextButton\")]')\n",
    "        next_page.click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df_books = pd.DataFrame({'title': book_title, 'author': book_author, 'length': book_length})\n",
    "df_books.to_csv('books_pagination.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97d0783e-1e8f-4c17-9804-9dd63d739630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['By: Colleen Hoover',\n",
       "  'By: Ryan Holiday',\n",
       "  'By: Freida McFadden',\n",
       "  'By: Sarah J. Maas',\n",
       "  'By: Luis Elizondo',\n",
       "  'By: Colleen Hoover',\n",
       "  'By: Sarah J. Maas',\n",
       "  'By: Amy Harmon',\n",
       "  'By: Rebecca Yarros',\n",
       "  'By: Rebecca Yarros',\n",
       "  'By: Sarah J. Maas',\n",
       "  'By: James S.A. Corey',\n",
       "  'By: J. D. Vance',\n",
       "  'By: Freida McFadden',\n",
       "  'By: Jennifer L. Armentrout',\n",
       "  'By: Freida McFadden',\n",
       "  'By: Morgan Housel',\n",
       "  'By: Brian Tyler Cohen',\n",
       "  'By: Shelby Van Pelt',\n",
       "  'By: Steve Benen'],\n",
       " ['Length: 11 hrs and 11 mins',\n",
       "  'Length: 6 hrs and 56 mins',\n",
       "  'Length: 9 hrs and 46 mins',\n",
       "  'Length: 23 hrs and 16 mins',\n",
       "  'Length: 10 hrs',\n",
       "  'Length: 8 hrs and 10 mins',\n",
       "  'Length: 25 hrs and 9 mins',\n",
       "  'Length: 13 hrs and 44 mins',\n",
       "  'Length: 21 hrs and 22 mins',\n",
       "  'Length: 28 hrs and 16 mins',\n",
       "  'Length: 26 hrs and 5 mins',\n",
       "  'Length: 14 hrs and 54 mins',\n",
       "  'Length: 6 hrs and 49 mins',\n",
       "  'Length: 11 hrs and 42 mins',\n",
       "  'Length: 37 hrs and 1 min',\n",
       "  'Length: 9 hrs and 44 mins',\n",
       "  'Length: 5 hrs and 55 mins',\n",
       "  'Length: 4 hrs and 38 mins',\n",
       "  'Length: 11 hrs and 16 mins',\n",
       "  'Length: 5 hrs and 38 mins'],\n",
       " ['1. It Ends with Us',\n",
       "  '2. Ego Is the Enemy',\n",
       "  '3. The Housemaid',\n",
       "  '4. A Court of Mist and Fury',\n",
       "  '5. Imminent',\n",
       "  '6. Verity',\n",
       "  '7. A Court of Wings and Ruin',\n",
       "  '8. The Outlaw Noble Salt',\n",
       "  '9. Fourth Wing',\n",
       "  '10. Iron Flame',\n",
       "  '11. A Court of Silver Flames',\n",
       "  '12. The Mercy of Gods',\n",
       "  '13. Hillbilly Elegy',\n",
       "  '14. The Housemaid Is Watching',\n",
       "  '15. Born of Blood and Ash',\n",
       "  \"16. The Housemaid's Secret\",\n",
       "  '17. The Psychology of Money',\n",
       "  '18. Shameless',\n",
       "  '19. Remarkably Bright Creatures',\n",
       "  '20. Ministry of Truth'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_author,book_length,book_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c248c5d-c8a4-449a-b779-c9fc2713f6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
